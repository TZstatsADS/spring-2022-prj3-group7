{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model II base.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import numpy as np\n",
        "import cv2\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Dropout, Flatten, concatenate\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ],
      "metadata": {
        "id": "rfUcaMUPZskP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBD30k53ZtSm",
        "outputId": "060c838b-a9f7-4f9f-9b6e-e5f20bdb39ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [DO NOT MODIFY THIS CELL]\n",
        "\n",
        "# load the images\n",
        "n_img = 50000\n",
        "n_noisy = 40000\n",
        "n_clean_noisy = n_img - n_noisy\n",
        "imgs = np.empty((n_img,32,32,3))\n",
        "\n",
        "# for i in range(n_img):\n",
        "#     img_fn = f'../data/train_data/images/{i+1:05d}.png' # I changed the path\n",
        "#     imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "a = {}\n",
        "zip_file = zipfile.ZipFile('/content/drive/MyDrive/data/train_data/imgs.npy.zip')\n",
        "imgs = np.load(zip_file.open(zip_file.namelist()[0]))\n",
        "\n",
        "# load the labels\n",
        "clean_labels = np.genfromtxt('/content/drive/MyDrive/data/train_data/clean_labels.csv', delimiter=',', dtype=\"int8\") # I changed the path\n",
        "noisy_labels = np.genfromtxt('/content/drive/MyDrive/data/train_data/noisy_labels.csv', delimiter=',', dtype=\"int8\") # I changed the path\n",
        "\n",
        "# imgs"
      ],
      "metadata": {
        "id": "e2kwL1D-Z2iH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvxiTxuWX9hJ",
        "outputId": "54b9e2d2-90d0-430c-fbb6-97706984ec23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "cleaned_labels = np.genfromtxt('/content/drive/MyDrive/Colab Notebooks/5243/cleaned_labels.csv', delimiter=',', dtype=\"int8\") # I changed the path\n",
        "cleaned_labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn2 = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "cnn2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "J2Fu3fSHaTtw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce learning rate when val_accuracy has stopped improving\n",
        "lr_reduce = K.callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                          factor=0.6,\n",
        "                                          patience=2,\n",
        "                                          verbose=1,\n",
        "                                          mode='max',\n",
        "                                          min_lr=1e-7)\n",
        "# stop training when val_accuracy has stopped improving\n",
        "early_stop = K.callbacks.EarlyStopping(monitor='val_accuracy',\n",
        "                                       patience=3,\n",
        "                                       verbose=1,\n",
        "                                       mode='max')\n",
        "# callback to save the Keras model and (best) weights obtained on an epoch basis. here, the trained (compiled) model is saved in the current working directory as ''\n",
        "checkpoint = K.callbacks.ModelCheckpoint('label_correction_model',\n",
        "                                         monitor='val_accuracy',\n",
        "                                         verbose=1,\n",
        "                                         save_weights_only=False,\n",
        "                                         save_best_only=True,\n",
        "                                         mode='max',\n",
        "                                         save_freq='epoch')"
      ],
      "metadata": {
        "id": "ngx_UVb3ausy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = imgs/255.0"
      ],
      "metadata": {
        "id": "iouCraiRcdif"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# document the start time\n",
        "start = time.time()\n",
        "\n",
        "# Fit the model using all data\n",
        "history = cnn2.fit(X, \n",
        "                  cleaned_labels,\n",
        "                  epochs = 10, \n",
        "                  validation_split = 0.2,\n",
        "                  shuffle=True,\n",
        "                  callbacks=[lr_reduce, early_stop, checkpoint],\n",
        "                  verbose=1)\n",
        "\n",
        "# document the training stop time\n",
        "stop = time.time()\n",
        "cnn2_trainingtime = stop - start\n",
        "print(f\"Training time: {cnn2_trainingtime}s\") # prints: Training time\n",
        "\n",
        "# Save the entire model as a SavedModel.\n",
        "cnn2.save(f'/content/drive/MyDrive/Colab Notebooks/5243/saved_model/model_II')\n",
        "\n",
        "#import pickle\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/5243/model_II_trainingtime', 'wb') as fp:\n",
        "    pickle.dump(cnn2_trainingtime, fp)\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/5243/model_II_historyfit', 'wb') as fp:\n",
        "    pickle.dump(history, fp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGqqL5kvajjk",
        "outputId": "1ad1923e-0054-46c8-d530-de4063bb07b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - ETA: 0s - loss: 0.5207 - accuracy: 0.8189\n",
            "Epoch 1: val_accuracy did not improve from 0.70070\n",
            "1250/1250 [==============================] - 56s 45ms/step - loss: 0.5207 - accuracy: 0.8189 - val_loss: 0.9459 - val_accuracy: 0.6925 - lr: 6.0000e-04\n",
            "Epoch 2/10\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.8287\n",
            "Epoch 2: val_accuracy did not improve from 0.70070\n",
            "1250/1250 [==============================] - 56s 45ms/step - loss: 0.4920 - accuracy: 0.8287 - val_loss: 0.9755 - val_accuracy: 0.6932 - lr: 6.0000e-04\n",
            "Epoch 3/10\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8383\n",
            "Epoch 3: val_accuracy improved from 0.70070 to 0.70130, saving model to label_correction_model\n",
            "INFO:tensorflow:Assets written to: label_correction_model/assets\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 0.4648 - accuracy: 0.8382 - val_loss: 0.9510 - val_accuracy: 0.7013 - lr: 6.0000e-04\n",
            "Epoch 4/10\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4351 - accuracy: 0.8482\n",
            "Epoch 4: val_accuracy did not improve from 0.70130\n",
            "1250/1250 [==============================] - 54s 43ms/step - loss: 0.4350 - accuracy: 0.8482 - val_loss: 0.9768 - val_accuracy: 0.6974 - lr: 6.0000e-04\n",
            "Epoch 5/10\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.4140 - accuracy: 0.8561\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.70130\n",
            "1250/1250 [==============================] - 54s 43ms/step - loss: 0.4139 - accuracy: 0.8561 - val_loss: 1.0543 - val_accuracy: 0.6908 - lr: 6.0000e-04\n",
            "Epoch 6/10\n",
            "1249/1250 [============================>.] - ETA: 0s - loss: 0.3519 - accuracy: 0.8810\n",
            "Epoch 6: val_accuracy did not improve from 0.70130\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 0.3518 - accuracy: 0.8810 - val_loss: 1.0475 - val_accuracy: 0.6958 - lr: 3.6000e-04\n",
            "Epoch 6: early stopping\n",
            "Training time: 330.4952185153961s\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab Notebooks/5243/saved_model/model_II/assets\n",
            "INFO:tensorflow:Assets written to: ram://b10e13e4-8e47-4d57-8a0e-9454d454b172/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to delete this\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "(X_train, y_train), (X_test,y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "y_train = y_train.reshape(-1,) \n",
        "y_test = y_test.reshape(-1,)\n",
        "def plot_sample(X, y, index):\n",
        "    plt.figure(figsize = (15,2))\n",
        "    plt.imshow(X[index])\n",
        "    plt.xlabel(classes[y[index]])\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "cnn2.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGD_ujEUZdms",
        "outputId": "6573533d-82c4-41f7-c59e-b0ec02783a8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 14ms/step - loss: 1.1262 - accuracy: 0.6869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1261730194091797, 0.6869000196456909]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}